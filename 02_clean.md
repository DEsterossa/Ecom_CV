# Clean Pipeline - Предсказание alpha канала

## Описание

Ноутбук для обучения модели предсказания alpha канала (значения 0..255) с использованием архитектуры U2NETP. Метрика качества - MSE (Mean Squared Error).

**Данные:**
- Обучающая выборка: MAGICK (train)
- Тестовая выборка: Kaggle test (orig_1024)

## Структура ноутбука

### 1. Imports

Импортируются необходимые библиотеки:
- `torch`, `torchvision` - для работы с нейронными сетями
- `PIL`, `numpy`, `pandas` - для обработки данных
- `scipy.ndimage` - для постпроцессинга
- `tqdm` - для прогресс-баров

### 2. CONFIG

Основные параметры конфигурации:

**Семена и устройство:**
- `SEED = 42` - для воспроизводимости
- `device` - автоматический выбор GPU/CPU

**Пути к данным:**
- `TRAIN_CSV` - CSV файл с путями к обучающим изображениям
- `VAL_CSV` - CSV файл с путями к валидационным изображениям
- `TEST_ROOT` - директория с тестовыми изображениями
- `MODEL_DIR` - директория для сохранения моделей

**Параметры обучения:**
- `TRAIN_SIZE = (512, 512)` - размер изображений при обучении
- `VAL_SIZE = (1024, 1024)` - размер изображений при валидации
- `TRAIN_BATCH = 4` - размер батча для обучения
- `VAL_BATCH = 1` - размер батча для валидации
- `NUM_EPOCHS = 8` - количество эпох
- `LR = 1e-4` - начальная скорость обучения
- `LIMIT_DATA = 10` - ограничение количества данных (для отладки)

### 3. Dataset + Transforms

#### 3.1. Airport X-ray Alpha аугментация

Реализована специальная аугментация `airport_xray_alpha`, которая симулирует эффект рентгеновского сканирования с использованием подхода DoG (Difference of Gaussians):

**Основные компоненты:**
- `compute_luma(rgb)` - вычисление яркости из RGB
- `gaussian_kernel_1d(sigma)` - создание 1D Gaussian ядра
- `gaussian_blur_2d(x, sigma)` - применение 2D Gaussian blur
- `airport_xray_alpha()` - основная функция аугментации

**Параметры аугментации:**
- `p=0.5` - вероятность применения аугментации
- `d_min_range=(0.55, 0.85)` - диапазон минимальной плотности
- `a_range=(0.15, 0.45)` - диапазон параметра a
- `sigma1_range=(1.0, 2.0)` - диапазон для первого Gaussian blur
- `sigma2_range=(6.0, 12.0)` - диапазон для второго Gaussian blur
- `s=0.06` - параметр нормализации

**Алгоритм:**
1. Вычисляется яркость (luma) из RGB изображения
2. Применяются два Gaussian blur с разными sigma
3. Вычисляется разность (DoG): `hi = g1 - g2`
4. Нормализация через tanh: `tex = (tanh(hi/s) + 1) / 2`
5. Вычисление плотности: `density = d_min + (1 - d_min) * (1 - a * tex)`
6. Применение к alpha каналу: `alpha_target = alpha_orig * density`

#### 3.2. JointAugment

Класс для совместной аугментации изображения и маски:

**Аугментации:**
- Random crop до размера `crop_size`
- Horizontal flip с вероятностью `p_flip`
- Поворот на угол до `max_rotate` градусов с вероятностью `p_rotate`
- Color jitter (brightness, contrast, saturation) только для изображения с вероятностью `p_color`

#### 3.3. CsvAlphaDataset

Датасет для загрузки данных из CSV файла.

**Параметры:**
- `csv_path` - путь к CSV файлу с колонками `image_path` и `alpha_path`
- `size` - размер изображений
- `normalize` - применение ImageNet нормализации
- `augment` - объект аугментации (JointAugment)
- `limit` - ограничение количества данных
- Параметры x-ray аугментации

**Возвращает:**
- `{"img": tensor, "mask": tensor}` - словарь с изображением и маской

**Особенности:**
- X-ray аугментация применяется после PIL аугментаций, но до нормализации
- Фон обнуляется: `mask = gt_alpha * obj`, где `obj = (gt_alpha > 0.1)`

#### 3.4. TestImageDataset

Датасет для тестовых изображений:
- Загружает все изображения из директории
- Применяет resize до указанного размера
- Применяет ImageNet нормализацию
- Возвращает `{"path": filename, "img": tensor}`

### 4. Model Init

Инициализация модели U2NETP:
- Загружается из директории `U-2-Net`
- Архитектура: `U2NETP(in_ch=3, out_ch=1)`
- Загружаются предобученные веса из `u2netp.pth`
- Модель переносится на GPU/CPU

### 5. Loss

Реализована сложная функция потерь `u2net_mse_loss` с несколькими компонентами:

**Основные компоненты:**

1. **Base MSE Loss** - базовая MSE между предсказанием и целевой маской

2. **Background-aware Loss** - штраф за "туман" на фоне:
   - `bg_mask = (gt <= 0.05)` - маска фона
   - `bg_penalty` - штраф за значения > 0.02 на фоне
   - `bg_mse` - MSE на фоне
   - `bg_loss = bg_mse + 2.0 * bg_penalty`

3. **Edge-aware Loss** - совпадение градиентов:
   - Использует Sobel оператор для вычисления градиентов
   - `edge_loss = |sobel(pred) - sobel(gt)|.mean()`

4. **Thin-aware Loss** - взвешенный loss для тонких деталей:
   - `thin_map()` - создает карту тонких зон (края + тонкие детали)
   - Использует эрозию для выделения "core" объекта
   - `thin = obj - core` - тонкие зоны
   - Веса: `w = 1.0 + 4.0 * thin`
   - Комбинация MSE и Charbonnier loss

5. **Gradient-aware Loss** - loss на градиенты внутри объекта:
   - Вычисляет магнитуду градиента через Sobel
   - Применяется только внутри объекта (`obj = gt > 0.1`)
   - `gradient_loss = |sobel_mag(pred) - sobel_mag(gt)|.mean()`

**Финальная формула:**
```
loss = base + 0.2 * edge_loss + 0.5 * bg_loss + 0.5 * thin_loss + 0.2 * gradient_loss
```

**Вспомогательные функции:**
- `sobel(x)` - Sobel оператор для тензоров (B, C, H, W)
- `sobel_mag(x)` - магнитуда градиента для 2D тензоров
- `erode(mask01, k)` - эрозия через min pooling
- `thin_map(alpha01, k, thr)` - карта тонких зон
- `charbonnier(x, eps)` - Charbonnier loss (smooth L1)

### 6. Train Loop

#### 6.1. Функции обучения

**train_epoch:**
- Обучение модели на одной эпохе
- Использует `u2net_mse_loss` для вычисления потерь
- Поддерживает AMP (Automatic Mixed Precision), но отключен по умолчанию
- Возвращает средние loss и MSE

**eval_epoch:**
- Валидация модели
- Вычисляет loss и метрику MSE
- Работает в режиме `torch.no_grad()`

#### 6.2. Цикл обучения

**Оптимизатор:**
- `AdamW` с learning rate `LR = 1e-4` и weight decay `1e-4`

**Scheduler:**
- `ReduceLROnPlateau` - уменьшает LR в 2 раза при отсутствии улучшения
- `patience=2` - ждет 2 эпохи без улучшения
- `factor=0.5` - коэффициент уменьшения LR

**Логика сохранения:**
- Сохраняется лучшая модель по валидационной MSE
- Используется функция `get_unique_path()` для избежания перезаписи
- Если файл существует, добавляется номер: `u2netp_best_2.pth`, `u2netp_best_3.pth`, и т.д.

**Результаты обучения (из вывода):**
- Epoch 1: train_mse=0.245148, val_mse=0.234155
- Epoch 8: train_mse=0.235724, val_mse=0.143636
- Лучшая модель сохранена с val_mse=0.143636

### 7. Infer + Submission

#### 7.1. Инференс на тестовых данных

**Процесс предсказания:**

1. **Flip-TTA (Test Time Augmentation):**
   - Предсказание на оригинальном изображении
   - Предсказание на горизонтально отраженном изображении
   - Усреднение результатов: `pred = (pred_orig + pred_flip) / 2`

2. **Компонентный постпроцесс:**
   - Бинаризация: `supp = (pred > 0.05)`
   - Поиск связных компонентов через `scipy.ndimage.label`
   - Для каждого компонента вычисляется:
     - `max_conf` - максимальная уверенность
     - `area` - площадь компонента
   - Сортировка по `(max_conf, area)` в убывающем порядке
   - Сохранение только топ-3 компонентов с `max_conf > 0.35`

3. **Дилатация:**
   - Применяется max pooling (kernel_size=7) для расширения маски
   - Это помогает сохранить края объектов

4. **Конвертация в формат submission:**
   - Масштабирование в диапазон [0, 255]
   - Конвертация в PIL Image
   - Кодирование в base64 PNG
   - Сохранение в CSV с колонками `filename` и `image_utf`

#### 7.2. Визуализация submission

Добавлен код для визуализации предсказанных масок из submission.csv:
- Декодирование base64 строк в PIL Image
- Отображение первых N изображений
- Вывод статистики (shape, dtype, min, max)

## Ключевые особенности реализации

1. **Специальная аугментация:** Airport X-ray alpha аугментация симулирует эффект рентгеновского сканирования, что важно для задачи предсказания прозрачности.

2. **Многоуровневая функция потерь:** Комбинация базового MSE с дополнительными компонентами для:
   - Защиты фона от "тумана"
   - Сохранения краев объектов
   - Сохранения тонких деталей
   - Сохранения градиентов внутри объекта

3. **Test Time Augmentation:** Использование Flip-TTA для улучшения предсказаний.

4. **Компонентный постпроцесс:** Фильтрация предсказаний по связным компонентам для удаления шума.

5. **Воспроизводимость:** Установка всех семян для детерминированного поведения.

## Параметры для настройки

**Аугментации:**
- `xray_aug_p=0.9` - вероятность x-ray аугментации (высокая для обучения)
- `p_flip=0.5`, `p_rotate=0.3`, `p_color=0.7` - вероятности различных аугментаций

**Loss веса:**
- `0.2` для edge_loss
- `0.5` для bg_loss
- `0.5` для thin_loss
- `0.2` для gradient_loss

**Постпроцесс:**
- Порог бинаризации: `0.05`
- Минимальная уверенность компонента: `0.35`
- Максимальное количество компонентов: `3`
- Размер ядра дилатации: `7`

## Зависимости

- PyTorch
- torchvision
- PIL/Pillow
- numpy
- pandas
- scipy
- tqdm
- matplotlib (для визуализации)
- U-2-Net (локальная копия архитектуры)

## Структура выходных файлов

- `outputs/experiments/exp_001/u2netp_best.pth` - лучшая модель
- `outputs/experiments/exp_001/submission.csv` - файл submission для Kaggle

